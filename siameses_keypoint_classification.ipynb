{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip install tensorflow --upgrade\n",
    "#!pip install gast --upgrade\n",
    "#!pip install astroid  --upgrade\n",
    "\n",
    "!pip install tensorflow 2.4.1\n",
    "#!pip install tensorflow==2.4.1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "RANDOM_SEED = 42"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pip list"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 各パス指定"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = 'model/keypoint_classifier/keypoint.csv'\n",
    "model_save_path = 'model/keypoint_classifier/keypoint_classifier.hdf5'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 分類数設定"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#NUM_CLASSES = 3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 学習データ読み込み"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#X_dataset = np.loadtxt(dataset, delimiter=',', dtype='float32', usecols=list(range(1, (21 * 2) + 1)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#y_dataset = np.loadtxt(dataset, delimiter=',', dtype='int32', usecols=(0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#X_train, X_test, y_train, y_test = train_test_split(X_dataset, y_dataset, train_size=0.75, random_state=RANDOM_SEED)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip install imutils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.datasets import mnist\n",
    "from imutils import build_montages\n",
    "import numpy as np\n",
    "import cv2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "ename": "IndentationError",
     "evalue": "unindent does not match any outer indentation level (<tokenize>, line 15)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;36m  File \u001b[1;32m\"<tokenize>\"\u001b[1;36m, line \u001b[1;32m15\u001b[0m\n\u001b[1;33m    for idxA in range(len(images)):\u001b[0m\n\u001b[1;37m    ^\u001b[0m\n\u001b[1;31mIndentationError\u001b[0m\u001b[1;31m:\u001b[0m unindent does not match any outer indentation level\n"
     ]
    }
   ],
   "source": [
    "# def make_pairs(images, labels):\n",
    "# \t# initialize two empty lists to hold the (image, image) pairs and\n",
    "# \t# labels to indicate if a pair is positive or negative\n",
    "# \tpairImages = []\n",
    "# \tpairLabels = [] \n",
    "#     # calculate the total number of classes present in the dataset\n",
    "# \t# and then build a list of indexes for each class label that\n",
    "# \t# provides the indexes for all examples with a given label\n",
    "# \tnumClasses = len(np.unique(labels))\n",
    "# \tidx = [np.where(labels == i)[0] for i in range(0, numClasses)]\n",
    "#     #print(idx)\n",
    "    \n",
    "#     # loop over all images\n",
    "    \n",
    "#     for idxA in range(len(images)):\n",
    "# \t\t# grab the current image and label belonging to the current\n",
    "# \t\t# iteration\n",
    "# \t\tcurrentImage = images[idxA]\n",
    "# \t\tlabel = labels[idxA]\n",
    "# \t\t# randomly pick an image that belongs to the *same* class\n",
    "# \t\t# label\n",
    "# \t\tidxB = np.random.choice(idx[label])\n",
    "# \t\tposImage = images[idxB]\n",
    "# \t\t# prepare a positive pair and update the images and labels\n",
    "# \t\t# lists, respectively\n",
    "# \t\tpairImages.append([currentImage, posImage])\n",
    "# \t\tpairLabels.append([1])\n",
    "#         # grab the indices for each of the class labels *not* equal to\n",
    "# \t\t# the current label and randomly pick an image corresponding\n",
    "# \t\t# to a label *not* equal to the current label\n",
    "# \t\tnegIdx = np.where(labels != label)[0]\n",
    "# \t\tnegImage = images[np.random.choice(negIdx)]\n",
    "# \t\t# prepare a negative pair of images and update our lists\n",
    "# \t\tpairImages.append([currentImage, negImage])\n",
    "# \t\tpairLabels.append([0])\n",
    "# \t# return a 2-tuple of our image pairs and labels\n",
    "# \treturn (np.array(pairImages), np.array(pairLabels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_pairs(images, labels):\n",
    "\t# initialize two empty lists to hold the (image, image) pairs and\n",
    "\t# labels to indicate if a pair is positive or negative\n",
    "\tpairImages = []\n",
    "\tpairLabels = [] \n",
    "    # calculate the total number of classes present in the dataset\n",
    "\t# and then build a list of indexes for each class label that\n",
    "\t# provides the indexes for all examples with a given label\n",
    "\tnumClasses = len(np.unique(labels))\n",
    "    \n",
    "\tidx = [np.where(labels == i)[0] for i in range(0, numClasses)]\n",
    "    #print(idx)\n",
    "    \n",
    "    # loop over all images\n",
    "    \n",
    "    for idxA in range(len(images)):\n",
    "\tfor idxA, image in enumerate(images):\n",
    "    \n",
    "        # grab the current image and label belonging to the current\n",
    "\t\t# iteration\n",
    "\t\tcurrentImage = images[idxA]\n",
    "\t\tlabel = labels[idxA]\n",
    "\t\t# randomly pick an image that belongs to the *same* class\n",
    "\t\t# label\n",
    "\t\tidxB = np.random.choice(idx[label])\n",
    "\t\tposImage = images[idxB]\n",
    "\t\t# prepare a positive pair and update the images and labels\n",
    "\t\t# lists, respectively\n",
    "\t\tpairImages.append([currentImage, posImage])\n",
    "\t\tpairLabels.append([1])\n",
    "        # grab the indices for each of the class labels *not* equal to\n",
    "\t\t# the current label and randomly pick an image corresponding\n",
    "\t\t# to a label *not* equal to the current label\n",
    "\t\tnegIdx = np.where(labels != label)[0]\n",
    "\t\tnegImage = images[np.random.choice(negIdx)]\n",
    "\t\t# prepare a negative pair of images and update our lists\n",
    "\t\tpairImages.append([currentImage, negImage])\n",
    "\t\tpairLabels.append([0])\n",
    "\t# return a 2-tuple of our image pairs and labels\n",
    "\treturn (np.array(pairImages), np.array(pairLabels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# make pairs\n",
    "# def mmake_pairs(x, y):\n",
    "#     num_classes = max(y) + 1\n",
    "#     digit_indices = [np.where(y == i)[0] for i in range(num_classes)]\n",
    "\n",
    "#     pairs = []\n",
    "#     labels = []\n",
    "\n",
    "#     for idx1 in range(len(x)):\n",
    "#         # add a matching example\n",
    "#         x1 = x[idx1]\n",
    "#         label1 = y[idx1]\n",
    "#         idx2 = random.choice(digit_indices[label1])\n",
    "#         x2 = x[idx2]\n",
    "        \n",
    "#         pairs += [[x1, x2]]\n",
    "#         labels += [1]\n",
    "    \n",
    "#         # add a not matching example\n",
    "#         label2 = random.randint(0, num_classes-1)\n",
    "#         while label2 == label1:\n",
    "#             label2 = random.randint(0, num_classes-1)\n",
    "\n",
    "#         idx2 = random.choice(digit_indices[label2])\n",
    "#         x2 = x[idx2]\n",
    "        \n",
    "#         pairs += [[x1, x2]]\n",
    "#         labels += [0]\n",
    "\n",
    "#     return np.array(pairs), np.array(labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_dataset = np.loadtxt(dataset, delimiter=',', dtype='float32', usecols=list(range(1, (21 * 2) + 1)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_dataset = np.loadtxt(dataset, delimiter=',', dtype='int32', usecols=(0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X_dataset, y_dataset, train_size=0.75, random_state=RANDOM_SEED)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train images shape (475, 42)\n",
      "lables train (475,)\n",
      "test images shape (159, 42)\n",
      "labels test (159,)\n",
      "42\n"
     ]
    }
   ],
   "source": [
    "print('train images shape',X_train.shape)\n",
    "print('lables train',y_train.shape)\n",
    "print('test images shape',X_test.shape)\n",
    "print('labels test',y_test.shape)\n",
    "\n",
    "print(len(X_train[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] loading MNIST dataset...\n",
      "[INFO] preparing positive and negative pairs...\n"
     ]
    }
   ],
   "source": [
    "# load MNIST dataset and scale the pixel values to the range of [0, 1]\n",
    "print(\"[INFO] loading MNIST dataset...\")\n",
    "#(trainX, trainY), (testX, testY) = mnist.load_data()\n",
    "# build the positive and negative image pairs\n",
    "print(\"[INFO] preparing positive and negative pairs...\")\n",
    "\n",
    "# (pairTrain, labelTrain) = make_pairs(trainX, trainY)\n",
    "# (pairTest, labelTest) = make_pairs(testX, testY)\n",
    "\n",
    "(pairTrain, labelTrain) = make_pairs(X_train, y_train)\n",
    "(pairTest, labelTest) = make_pairs(X_test, y_test)\n",
    "# initialize the list of images that will be used when building our\n",
    "# montage\n",
    "images = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pairs_train, labels_train = mmake_pairs(X_train, y_train)\n",
    "# pairs_test, labels_test = mmake_pairs(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(pairs_train.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(950, 2, 42)\n",
      "(950, 1)\n",
      "(318, 2, 42)\n",
      "(318, 1)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "print(pairTrain.shape)\n",
    "print(labelTrain.shape)\n",
    "\n",
    "print(pairTest.shape)\n",
    "print(labelTest.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install wandb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install matplotlib\n",
    "!pip install pandas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "import numpy as np\n",
    "from tensorflow import keras\n",
    "import wandb\n",
    "from wandb.keras import WandbCallback\n",
    "from tensorflow.keras.models import Sequential, Model\n",
    "from tensorflow.keras.layers import Flatten, Dense, Concatenate, Dot, Lambda, Input, Dropout\n",
    "from tensorflow.keras.datasets import mnist\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model 1\n",
    "seq1 = Sequential()\n",
    "seq1.add(Flatten(input_shape=(42,)))\n",
    "seq1.add(Dense(128, activation='relu'))\n",
    "\n",
    "seq2 = Sequential()\n",
    "seq2.add(Flatten(input_shape=(42,)))\n",
    "seq2.add(Dense(128, activation='relu'))\n",
    "\n",
    "merge_layer = Concatenate()([seq1.output, seq2.output])\n",
    "dense_layer = Dense(1, activation=\"sigmoid\")(merge_layer)\n",
    "model = Model(inputs=[seq1.input, seq2.input], outputs=dense_layer)\n",
    "\n",
    "# model = tf.keras.models.Sequential([\n",
    "#     tf.keras.layers.Input((21 * 2, )),\n",
    "#     tf.keras.layers.Dropout(0.2),\n",
    "#     tf.keras.layers.Dense(20, activation='relu'),\n",
    "#     tf.keras.layers.Dropout(0.4),\n",
    "#     tf.keras.layers.Dense(10, activation='relu'),\n",
    "#     tf.keras.layers.Dense(NUM_CLASSES, activation='softmax')\n",
    "# ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Model 2\n",
    "from tensorflow.keras import backend as K\n",
    "\n",
    "def euclidean_distance(vects):\n",
    "    x, y = vects\n",
    "    sum_square = K.sum(K.square(x - y), axis=1, keepdims=True)\n",
    "    return K.sqrt(K.maximum(sum_square, K.epsilon()))\n",
    "\n",
    "\n",
    "input = Input((42,))\n",
    "x = Flatten()(input)\n",
    "x = Dropout(0.1)(x)\n",
    "x = Dense(128, activation='relu')(x)\n",
    "x = Dropout(0.2)(x)\n",
    "dense = Model(input, x)\n",
    "\n",
    "input1 = Input((42,))\n",
    "input2 = Input((42,))\n",
    "\n",
    "dense1 = dense(input1)\n",
    "dense2 = dense(input2)\n",
    "\n",
    "merge_layer = Lambda(euclidean_distance)([dense1,dense2])\n",
    "dense_layer = Dense(1, activation=\"sigmoid\")(merge_layer)\n",
    "model = Model(inputs=[input1, input2], outputs=dense_layer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_19\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_26 (InputLayer)           [(None, 42)]         0                                            \n",
      "__________________________________________________________________________________________________\n",
      "input_27 (InputLayer)           [(None, 42)]         0                                            \n",
      "__________________________________________________________________________________________________\n",
      "model_18 (Functional)           (None, 128)          5504        input_26[0][0]                   \n",
      "                                                                 input_27[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "lambda_7 (Lambda)               (None, 1)            0           model_18[0][0]                   \n",
      "                                                                 model_18[1][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "dense_25 (Dense)                (None, 1)            2           lambda_7[0][0]                   \n",
      "==================================================================================================\n",
      "Total params: 5,506\n",
      "Trainable params: 5,506\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.compile(loss = \"binary_crossentropy\", optimizer=\"adam\", metrics=[\"accuracy\"])\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/500\n",
      "60/60 [==============================] - 0s 1ms/step - loss: 1.3086 - accuracy: 0.4799\n",
      "Epoch 2/500\n",
      "60/60 [==============================] - 0s 1ms/step - loss: 0.7120 - accuracy: 0.5391\n",
      "Epoch 3/500\n",
      "60/60 [==============================] - 0s 1ms/step - loss: 0.6988 - accuracy: 0.4797\n",
      "Epoch 4/500\n",
      "60/60 [==============================] - 0s 1ms/step - loss: 0.6975 - accuracy: 0.5126\n",
      "Epoch 5/500\n",
      "60/60 [==============================] - 0s 1ms/step - loss: 0.6963 - accuracy: 0.4699\n",
      "Epoch 6/500\n",
      "60/60 [==============================] - 0s 1ms/step - loss: 0.6931 - accuracy: 0.5098\n",
      "Epoch 7/500\n",
      "60/60 [==============================] - 0s 1ms/step - loss: 0.6949 - accuracy: 0.5100\n",
      "Epoch 8/500\n",
      "60/60 [==============================] - 0s 1ms/step - loss: 0.6991 - accuracy: 0.4290\n",
      "Epoch 9/500\n",
      "60/60 [==============================] - 0s 1ms/step - loss: 0.6966 - accuracy: 0.4804\n",
      "Epoch 10/500\n",
      "60/60 [==============================] - 0s 1ms/step - loss: 0.6963 - accuracy: 0.4748\n",
      "Epoch 11/500\n",
      "60/60 [==============================] - 0s 1ms/step - loss: 0.6937 - accuracy: 0.4946\n",
      "Epoch 12/500\n",
      "60/60 [==============================] - 0s 1ms/step - loss: 0.6964 - accuracy: 0.4853\n",
      "Epoch 13/500\n",
      "60/60 [==============================] - 0s 1ms/step - loss: 0.6991 - accuracy: 0.4551\n",
      "Epoch 14/500\n",
      "60/60 [==============================] - 0s 1ms/step - loss: 0.6988 - accuracy: 0.4537\n",
      "Epoch 15/500\n",
      "60/60 [==============================] - 0s 1ms/step - loss: 0.6965 - accuracy: 0.4964\n",
      "Epoch 16/500\n",
      "60/60 [==============================] - 0s 1ms/step - loss: 0.6955 - accuracy: 0.5015\n",
      "Epoch 17/500\n",
      "60/60 [==============================] - 0s 1ms/step - loss: 0.6939 - accuracy: 0.4936\n",
      "Epoch 18/500\n",
      "60/60 [==============================] - 0s 1ms/step - loss: 0.6913 - accuracy: 0.5304\n",
      "Epoch 19/500\n",
      "60/60 [==============================] - 0s 1ms/step - loss: 0.6959 - accuracy: 0.4960\n",
      "Epoch 20/500\n",
      "60/60 [==============================] - 0s 1ms/step - loss: 0.6929 - accuracy: 0.5393\n",
      "Epoch 21/500\n",
      "60/60 [==============================] - 0s 1ms/step - loss: 0.6945 - accuracy: 0.5037\n",
      "Epoch 22/500\n",
      "60/60 [==============================] - 0s 1ms/step - loss: 0.6895 - accuracy: 0.5371\n",
      "Epoch 23/500\n",
      "60/60 [==============================] - 0s 1ms/step - loss: 0.6965 - accuracy: 0.4909\n",
      "Epoch 24/500\n",
      "60/60 [==============================] - 0s 1ms/step - loss: 0.6952 - accuracy: 0.4721\n",
      "Epoch 25/500\n",
      "60/60 [==============================] - 0s 1ms/step - loss: 0.6926 - accuracy: 0.5277\n",
      "Epoch 26/500\n",
      "60/60 [==============================] - 0s 1ms/step - loss: 0.6945 - accuracy: 0.5298\n",
      "Epoch 27/500\n",
      "60/60 [==============================] - 0s 1ms/step - loss: 0.6981 - accuracy: 0.4837\n",
      "Epoch 28/500\n",
      "60/60 [==============================] - 0s 1ms/step - loss: 0.7006 - accuracy: 0.4585\n",
      "Epoch 29/500\n",
      "60/60 [==============================] - 0s 1ms/step - loss: 0.6934 - accuracy: 0.5213\n",
      "Epoch 30/500\n",
      "60/60 [==============================] - 0s 1ms/step - loss: 0.6926 - accuracy: 0.5204\n",
      "Epoch 31/500\n",
      "60/60 [==============================] - 0s 1ms/step - loss: 0.6910 - accuracy: 0.5369\n",
      "Epoch 32/500\n",
      "60/60 [==============================] - 0s 1ms/step - loss: 0.6921 - accuracy: 0.5173\n",
      "Epoch 33/500\n",
      "60/60 [==============================] - 0s 1ms/step - loss: 0.6927 - accuracy: 0.5094\n",
      "Epoch 34/500\n",
      "60/60 [==============================] - 0s 1ms/step - loss: 0.6939 - accuracy: 0.5299\n",
      "Epoch 35/500\n",
      "60/60 [==============================] - 0s 1ms/step - loss: 0.6942 - accuracy: 0.4966\n",
      "Epoch 36/500\n",
      "60/60 [==============================] - 0s 1ms/step - loss: 0.6949 - accuracy: 0.4844\n",
      "Epoch 37/500\n",
      "60/60 [==============================] - 0s 1ms/step - loss: 0.6918 - accuracy: 0.5224\n",
      "Epoch 38/500\n",
      "60/60 [==============================] - 0s 1ms/step - loss: 0.6914 - accuracy: 0.5397\n",
      "Epoch 39/500\n",
      "60/60 [==============================] - 0s 1ms/step - loss: 0.6930 - accuracy: 0.4866\n",
      "Epoch 40/500\n",
      "60/60 [==============================] - 0s 1ms/step - loss: 0.6940 - accuracy: 0.4886\n",
      "Epoch 41/500\n",
      "60/60 [==============================] - 0s 1ms/step - loss: 0.6930 - accuracy: 0.5247\n",
      "Epoch 42/500\n",
      "60/60 [==============================] - 0s 1ms/step - loss: 0.7006 - accuracy: 0.5045\n",
      "Epoch 43/500\n",
      "60/60 [==============================] - 0s 1ms/step - loss: 0.6907 - accuracy: 0.5378\n",
      "Epoch 44/500\n",
      "60/60 [==============================] - 0s 1ms/step - loss: 0.6944 - accuracy: 0.4900\n",
      "Epoch 45/500\n",
      "60/60 [==============================] - 0s 1ms/step - loss: 0.6929 - accuracy: 0.5089\n",
      "Epoch 46/500\n",
      "60/60 [==============================] - 0s 1ms/step - loss: 0.6907 - accuracy: 0.4933\n",
      "Epoch 47/500\n",
      "60/60 [==============================] - 0s 1ms/step - loss: 0.6943 - accuracy: 0.5093\n",
      "Epoch 48/500\n",
      "60/60 [==============================] - 0s 1ms/step - loss: 0.6943 - accuracy: 0.4972\n",
      "Epoch 49/500\n",
      "60/60 [==============================] - 0s 1ms/step - loss: 0.6943 - accuracy: 0.4825\n",
      "Epoch 50/500\n",
      "60/60 [==============================] - 0s 1ms/step - loss: 0.6940 - accuracy: 0.5226\n",
      "Epoch 51/500\n",
      "60/60 [==============================] - 0s 1ms/step - loss: 0.6939 - accuracy: 0.4901\n",
      "Epoch 52/500\n",
      "60/60 [==============================] - 0s 1ms/step - loss: 0.6946 - accuracy: 0.4871\n",
      "Epoch 53/500\n",
      "60/60 [==============================] - 0s 1ms/step - loss: 0.6941 - accuracy: 0.4880\n",
      "Epoch 54/500\n",
      "60/60 [==============================] - 0s 1ms/step - loss: 0.6911 - accuracy: 0.5251\n",
      "Epoch 55/500\n",
      "60/60 [==============================] - 0s 1ms/step - loss: 0.6970 - accuracy: 0.5009\n",
      "Epoch 56/500\n",
      "60/60 [==============================] - 0s 1ms/step - loss: 0.6941 - accuracy: 0.4802\n",
      "Epoch 57/500\n",
      "60/60 [==============================] - 0s 1ms/step - loss: 0.6946 - accuracy: 0.4922\n",
      "Epoch 58/500\n",
      "60/60 [==============================] - 0s 1ms/step - loss: 0.6935 - accuracy: 0.5170\n",
      "Epoch 59/500\n",
      "60/60 [==============================] - 0s 1ms/step - loss: 0.6934 - accuracy: 0.5101\n",
      "Epoch 60/500\n",
      "60/60 [==============================] - 0s 1ms/step - loss: 0.6937 - accuracy: 0.4938\n",
      "Epoch 61/500\n",
      "60/60 [==============================] - 0s 1ms/step - loss: 0.6922 - accuracy: 0.5197\n",
      "Epoch 62/500\n",
      "60/60 [==============================] - 0s 1ms/step - loss: 0.6949 - accuracy: 0.4787\n",
      "Epoch 63/500\n",
      "60/60 [==============================] - 0s 1ms/step - loss: 0.6951 - accuracy: 0.4936\n",
      "Epoch 64/500\n",
      "60/60 [==============================] - 0s 1ms/step - loss: 0.6951 - accuracy: 0.4924\n",
      "Epoch 65/500\n",
      "60/60 [==============================] - 0s 1ms/step - loss: 0.6929 - accuracy: 0.5059\n",
      "Epoch 66/500\n",
      "60/60 [==============================] - 0s 1ms/step - loss: 0.6944 - accuracy: 0.4903\n",
      "Epoch 67/500\n",
      "60/60 [==============================] - 0s 1ms/step - loss: 0.6924 - accuracy: 0.5053\n",
      "Epoch 68/500\n",
      "60/60 [==============================] - 0s 1ms/step - loss: 0.6927 - accuracy: 0.5193\n",
      "Epoch 69/500\n",
      "60/60 [==============================] - 0s 1ms/step - loss: 0.6949 - accuracy: 0.4794\n",
      "Epoch 70/500\n",
      "60/60 [==============================] - 0s 1ms/step - loss: 0.6934 - accuracy: 0.4906\n",
      "Epoch 71/500\n",
      "60/60 [==============================] - 0s 1ms/step - loss: 0.6939 - accuracy: 0.5048\n",
      "Epoch 72/500\n",
      "60/60 [==============================] - 0s 1ms/step - loss: 0.6939 - accuracy: 0.5320\n",
      "Epoch 73/500\n",
      "60/60 [==============================] - 0s 1ms/step - loss: 0.6937 - accuracy: 0.5221\n",
      "Epoch 74/500\n",
      "60/60 [==============================] - 0s 1ms/step - loss: 0.6957 - accuracy: 0.4754\n",
      "Epoch 75/500\n",
      "60/60 [==============================] - 0s 1ms/step - loss: 0.6930 - accuracy: 0.5002\n",
      "Epoch 76/500\n",
      "60/60 [==============================] - 0s 1ms/step - loss: 0.6932 - accuracy: 0.5118\n",
      "Epoch 77/500\n",
      "60/60 [==============================] - 0s 1ms/step - loss: 0.6932 - accuracy: 0.4954\n",
      "Epoch 78/500\n",
      "60/60 [==============================] - 0s 1ms/step - loss: 0.6934 - accuracy: 0.5054\n",
      "Epoch 79/500\n",
      "60/60 [==============================] - 0s 1ms/step - loss: 0.6929 - accuracy: 0.5023\n",
      "Epoch 80/500\n",
      "60/60 [==============================] - 0s 1ms/step - loss: 0.6922 - accuracy: 0.5072\n",
      "Epoch 81/500\n",
      "60/60 [==============================] - 0s 1ms/step - loss: 0.6930 - accuracy: 0.5117\n",
      "Epoch 82/500\n",
      "60/60 [==============================] - 0s 1ms/step - loss: 0.6927 - accuracy: 0.5136\n",
      "Epoch 83/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "60/60 [==============================] - 0s 1ms/step - loss: 0.6935 - accuracy: 0.5248\n",
      "Epoch 84/500\n",
      "60/60 [==============================] - 0s 1ms/step - loss: 0.6933 - accuracy: 0.4915\n",
      "Epoch 85/500\n",
      "60/60 [==============================] - 0s 1ms/step - loss: 0.6930 - accuracy: 0.5300\n",
      "Epoch 86/500\n",
      "60/60 [==============================] - 0s 1ms/step - loss: 0.6931 - accuracy: 0.4836\n",
      "Epoch 87/500\n",
      "60/60 [==============================] - 0s 1ms/step - loss: 0.6945 - accuracy: 0.4868\n",
      "Epoch 88/500\n",
      "60/60 [==============================] - 0s 1ms/step - loss: 0.6929 - accuracy: 0.5182\n",
      "Epoch 89/500\n",
      "60/60 [==============================] - 0s 1ms/step - loss: 0.6928 - accuracy: 0.5075\n",
      "Epoch 90/500\n",
      "60/60 [==============================] - 0s 1ms/step - loss: 0.6939 - accuracy: 0.4881\n",
      "Epoch 91/500\n",
      "60/60 [==============================] - 0s 1ms/step - loss: 0.6931 - accuracy: 0.5199\n",
      "Epoch 92/500\n",
      "60/60 [==============================] - 0s 1ms/step - loss: 0.6936 - accuracy: 0.4954\n",
      "Epoch 93/500\n",
      "60/60 [==============================] - 0s 1ms/step - loss: 0.6940 - accuracy: 0.5027\n",
      "Epoch 94/500\n",
      "60/60 [==============================] - 0s 1ms/step - loss: 0.6946 - accuracy: 0.4745\n",
      "Epoch 95/500\n",
      "60/60 [==============================] - 0s 1ms/step - loss: 0.6936 - accuracy: 0.4794\n",
      "Epoch 96/500\n",
      "60/60 [==============================] - 0s 1ms/step - loss: 0.6929 - accuracy: 0.5198\n",
      "Epoch 97/500\n",
      "60/60 [==============================] - 0s 1ms/step - loss: 0.6931 - accuracy: 0.4900\n",
      "Epoch 98/500\n",
      "60/60 [==============================] - 0s 1ms/step - loss: 0.6928 - accuracy: 0.5010\n",
      "Epoch 99/500\n",
      "60/60 [==============================] - 0s 1ms/step - loss: 0.6928 - accuracy: 0.4619\n",
      "Epoch 100/500\n",
      "60/60 [==============================] - 0s 1ms/step - loss: 0.6938 - accuracy: 0.4957\n",
      "Epoch 101/500\n",
      "60/60 [==============================] - 0s 1ms/step - loss: 0.6933 - accuracy: 0.5026\n",
      "Epoch 102/500\n",
      "60/60 [==============================] - 0s 1ms/step - loss: 0.6933 - accuracy: 0.5079\n",
      "Epoch 103/500\n",
      "60/60 [==============================] - 0s 1ms/step - loss: 0.6919 - accuracy: 0.5059\n",
      "Epoch 104/500\n",
      "60/60 [==============================] - 0s 1ms/step - loss: 0.6943 - accuracy: 0.4965\n",
      "Epoch 105/500\n",
      "60/60 [==============================] - 0s 1ms/step - loss: 0.6928 - accuracy: 0.5345\n",
      "Epoch 106/500\n",
      "60/60 [==============================] - 0s 1ms/step - loss: 0.6940 - accuracy: 0.4992\n",
      "Epoch 107/500\n",
      "60/60 [==============================] - 0s 1ms/step - loss: 0.6937 - accuracy: 0.4923\n",
      "Epoch 108/500\n",
      "60/60 [==============================] - 0s 1ms/step - loss: 0.6942 - accuracy: 0.4924\n",
      "Epoch 109/500\n",
      "60/60 [==============================] - 0s 1ms/step - loss: 0.6933 - accuracy: 0.5030\n",
      "Epoch 110/500\n",
      "60/60 [==============================] - 0s 1ms/step - loss: 0.6934 - accuracy: 0.5058\n",
      "Epoch 111/500\n",
      "60/60 [==============================] - 0s 1ms/step - loss: 0.6931 - accuracy: 0.5095\n",
      "Epoch 112/500\n",
      "60/60 [==============================] - 0s 1ms/step - loss: 0.6928 - accuracy: 0.5203\n",
      "Epoch 113/500\n",
      "60/60 [==============================] - 0s 1ms/step - loss: 0.6942 - accuracy: 0.4927\n",
      "Epoch 114/500\n",
      "60/60 [==============================] - 0s 1ms/step - loss: 0.6924 - accuracy: 0.5064\n",
      "Epoch 115/500\n",
      "60/60 [==============================] - 0s 1ms/step - loss: 0.6918 - accuracy: 0.5384\n",
      "Epoch 116/500\n",
      "60/60 [==============================] - 0s 1ms/step - loss: 0.6911 - accuracy: 0.5261\n",
      "Epoch 117/500\n",
      "60/60 [==============================] - 0s 1ms/step - loss: 0.6948 - accuracy: 0.5086\n",
      "Epoch 118/500\n",
      "60/60 [==============================] - 0s 1ms/step - loss: 0.6927 - accuracy: 0.5017\n",
      "Epoch 119/500\n",
      "60/60 [==============================] - 0s 1ms/step - loss: 0.6940 - accuracy: 0.4950\n",
      "Epoch 120/500\n",
      "60/60 [==============================] - 0s 1ms/step - loss: 0.6932 - accuracy: 0.5163\n",
      "Epoch 121/500\n",
      "60/60 [==============================] - 0s 1ms/step - loss: 0.6947 - accuracy: 0.5024\n",
      "Epoch 122/500\n",
      "60/60 [==============================] - 0s 1ms/step - loss: 0.6909 - accuracy: 0.5296\n",
      "Epoch 123/500\n",
      "60/60 [==============================] - 0s 1ms/step - loss: 0.6944 - accuracy: 0.4927\n",
      "Epoch 124/500\n",
      "60/60 [==============================] - 0s 1ms/step - loss: 0.6923 - accuracy: 0.5026\n",
      "Epoch 125/500\n",
      "60/60 [==============================] - 0s 1ms/step - loss: 0.6934 - accuracy: 0.5063\n",
      "Epoch 126/500\n",
      "60/60 [==============================] - 0s 1ms/step - loss: 0.6945 - accuracy: 0.5025\n",
      "Epoch 127/500\n",
      "60/60 [==============================] - 0s 1ms/step - loss: 0.6928 - accuracy: 0.5425\n",
      "Epoch 128/500\n",
      "60/60 [==============================] - 0s 1ms/step - loss: 0.6924 - accuracy: 0.5195\n",
      "Epoch 129/500\n",
      "60/60 [==============================] - 0s 1ms/step - loss: 0.6941 - accuracy: 0.4828\n",
      "Epoch 130/500\n",
      "60/60 [==============================] - 0s 1ms/step - loss: 0.6932 - accuracy: 0.4925\n",
      "Epoch 131/500\n",
      "60/60 [==============================] - 0s 1ms/step - loss: 0.6941 - accuracy: 0.5088\n",
      "Epoch 132/500\n",
      "60/60 [==============================] - 0s 1ms/step - loss: 0.6942 - accuracy: 0.4990\n",
      "Epoch 133/500\n",
      "60/60 [==============================] - 0s 1ms/step - loss: 0.6932 - accuracy: 0.5153\n",
      "Epoch 134/500\n",
      "60/60 [==============================] - 0s 1ms/step - loss: 0.6940 - accuracy: 0.4804\n",
      "Epoch 135/500\n",
      "60/60 [==============================] - 0s 1ms/step - loss: 0.6928 - accuracy: 0.5035\n",
      "Epoch 136/500\n",
      "60/60 [==============================] - 0s 1ms/step - loss: 0.6925 - accuracy: 0.4907\n",
      "Epoch 137/500\n",
      "60/60 [==============================] - 0s 1ms/step - loss: 0.6932 - accuracy: 0.5021\n",
      "Epoch 138/500\n",
      "60/60 [==============================] - 0s 1ms/step - loss: 0.6928 - accuracy: 0.4957\n",
      "Epoch 139/500\n",
      "60/60 [==============================] - 0s 1ms/step - loss: 0.6926 - accuracy: 0.5029\n",
      "Epoch 140/500\n",
      "60/60 [==============================] - 0s 1ms/step - loss: 0.6924 - accuracy: 0.4969\n",
      "Epoch 141/500\n",
      "60/60 [==============================] - 0s 1ms/step - loss: 0.6929 - accuracy: 0.5043\n",
      "Epoch 142/500\n",
      "60/60 [==============================] - 0s 1ms/step - loss: 0.6935 - accuracy: 0.4921\n",
      "Epoch 143/500\n",
      "60/60 [==============================] - 0s 1ms/step - loss: 0.6934 - accuracy: 0.4991\n",
      "Epoch 144/500\n",
      "60/60 [==============================] - 0s 1ms/step - loss: 0.6943 - accuracy: 0.4936\n",
      "Epoch 145/500\n",
      "60/60 [==============================] - 0s 1ms/step - loss: 0.6931 - accuracy: 0.4993\n",
      "Epoch 146/500\n",
      "60/60 [==============================] - 0s 1ms/step - loss: 0.6937 - accuracy: 0.5187\n",
      "Epoch 147/500\n",
      "60/60 [==============================] - 0s 1ms/step - loss: 0.6939 - accuracy: 0.5066\n",
      "Epoch 148/500\n",
      "60/60 [==============================] - 0s 1ms/step - loss: 0.6931 - accuracy: 0.5117\n",
      "Epoch 149/500\n",
      "60/60 [==============================] - 0s 1ms/step - loss: 0.6922 - accuracy: 0.5081\n",
      "Epoch 150/500\n",
      "60/60 [==============================] - 0s 1ms/step - loss: 0.6942 - accuracy: 0.4721\n",
      "Epoch 151/500\n",
      "60/60 [==============================] - 0s 1ms/step - loss: 0.6933 - accuracy: 0.5345\n",
      "Epoch 152/500\n",
      "60/60 [==============================] - 0s 1ms/step - loss: 0.6919 - accuracy: 0.5306\n",
      "Epoch 153/500\n",
      "60/60 [==============================] - 0s 1ms/step - loss: 0.6930 - accuracy: 0.5046\n",
      "Epoch 154/500\n",
      "60/60 [==============================] - 0s 1ms/step - loss: 0.6941 - accuracy: 0.4920\n",
      "Epoch 155/500\n",
      "60/60 [==============================] - 0s 1ms/step - loss: 0.6923 - accuracy: 0.5103\n",
      "Epoch 156/500\n",
      "60/60 [==============================] - 0s 1ms/step - loss: 0.6938 - accuracy: 0.4946\n",
      "Epoch 157/500\n",
      "60/60 [==============================] - 0s 1ms/step - loss: 0.6926 - accuracy: 0.5226\n",
      "Epoch 158/500\n",
      "60/60 [==============================] - 0s 1ms/step - loss: 0.6930 - accuracy: 0.4953\n",
      "Epoch 159/500\n",
      "60/60 [==============================] - 0s 1ms/step - loss: 0.6909 - accuracy: 0.5653\n",
      "Epoch 160/500\n",
      "60/60 [==============================] - 0s 1ms/step - loss: 0.6932 - accuracy: 0.5060\n",
      "Epoch 161/500\n",
      "60/60 [==============================] - 0s 1ms/step - loss: 0.6934 - accuracy: 0.4865\n",
      "Epoch 162/500\n",
      "60/60 [==============================] - 0s 1ms/step - loss: 0.6941 - accuracy: 0.5089\n",
      "Epoch 163/500\n",
      "60/60 [==============================] - 0s 1ms/step - loss: 0.6936 - accuracy: 0.5242\n",
      "Epoch 164/500\n",
      "60/60 [==============================] - 0s 1ms/step - loss: 0.6935 - accuracy: 0.4759\n",
      "Epoch 165/500\n",
      "60/60 [==============================] - 0s 1ms/step - loss: 0.6942 - accuracy: 0.4763\n",
      "Epoch 166/500\n",
      "60/60 [==============================] - 0s 1ms/step - loss: 0.6927 - accuracy: 0.5153\n",
      "Epoch 167/500\n",
      "60/60 [==============================] - 0s 1ms/step - loss: 0.6933 - accuracy: 0.4971\n",
      "Epoch 168/500\n",
      "60/60 [==============================] - 0s 1ms/step - loss: 0.6924 - accuracy: 0.5041\n",
      "Epoch 169/500\n",
      "60/60 [==============================] - 0s 1ms/step - loss: 0.6917 - accuracy: 0.5201\n",
      "Epoch 170/500\n",
      "60/60 [==============================] - 0s 1ms/step - loss: 0.6946 - accuracy: 0.4844\n",
      "Epoch 171/500\n",
      "60/60 [==============================] - 0s 1ms/step - loss: 0.6932 - accuracy: 0.4918\n",
      "Epoch 172/500\n",
      "60/60 [==============================] - 0s 1ms/step - loss: 0.6927 - accuracy: 0.5334\n",
      "Epoch 173/500\n",
      "60/60 [==============================] - 0s 1ms/step - loss: 0.6927 - accuracy: 0.5020\n",
      "Epoch 174/500\n",
      "60/60 [==============================] - 0s 1ms/step - loss: 0.6949 - accuracy: 0.5032\n",
      "Epoch 175/500\n",
      "60/60 [==============================] - 0s 1ms/step - loss: 0.6932 - accuracy: 0.4992\n",
      "Epoch 176/500\n",
      "60/60 [==============================] - 0s 1ms/step - loss: 0.6929 - accuracy: 0.5341\n",
      "Epoch 177/500\n",
      "60/60 [==============================] - 0s 1ms/step - loss: 0.6944 - accuracy: 0.4974\n",
      "Epoch 178/500\n",
      "60/60 [==============================] - 0s 1ms/step - loss: 0.6914 - accuracy: 0.5284\n",
      "Epoch 179/500\n",
      "60/60 [==============================] - 0s 1ms/step - loss: 0.6917 - accuracy: 0.5004\n",
      "Epoch 180/500\n",
      "60/60 [==============================] - 0s 1ms/step - loss: 0.6925 - accuracy: 0.5115\n",
      "Epoch 181/500\n",
      "60/60 [==============================] - 0s 1ms/step - loss: 0.6928 - accuracy: 0.5306\n",
      "Epoch 182/500\n",
      "60/60 [==============================] - 0s 1ms/step - loss: 0.6909 - accuracy: 0.5351\n",
      "Epoch 183/500\n",
      "60/60 [==============================] - 0s 1ms/step - loss: 0.6937 - accuracy: 0.5087\n",
      "Epoch 184/500\n",
      "60/60 [==============================] - 0s 1ms/step - loss: 0.6920 - accuracy: 0.5192\n",
      "Epoch 185/500\n",
      "60/60 [==============================] - 0s 1ms/step - loss: 0.6944 - accuracy: 0.5140\n",
      "Epoch 186/500\n",
      "60/60 [==============================] - 0s 1ms/step - loss: 0.6925 - accuracy: 0.5173\n",
      "Epoch 187/500\n",
      "60/60 [==============================] - 0s 1ms/step - loss: 0.6915 - accuracy: 0.5108\n",
      "Epoch 188/500\n",
      "60/60 [==============================] - 0s 1ms/step - loss: 0.6922 - accuracy: 0.5247\n",
      "Epoch 189/500\n",
      "60/60 [==============================] - 0s 1ms/step - loss: 0.6930 - accuracy: 0.5175\n",
      "Epoch 190/500\n",
      "60/60 [==============================] - 0s 1ms/step - loss: 0.6932 - accuracy: 0.5087\n",
      "Epoch 191/500\n",
      "60/60 [==============================] - 0s 1ms/step - loss: 0.6920 - accuracy: 0.5306\n",
      "Epoch 192/500\n",
      "60/60 [==============================] - 0s 1ms/step - loss: 0.6936 - accuracy: 0.4963\n",
      "Epoch 193/500\n",
      "60/60 [==============================] - 0s 1ms/step - loss: 0.6912 - accuracy: 0.5226\n",
      "Epoch 194/500\n",
      "60/60 [==============================] - 0s 1ms/step - loss: 0.6938 - accuracy: 0.4969\n",
      "Epoch 195/500\n",
      "60/60 [==============================] - 0s 1ms/step - loss: 0.6931 - accuracy: 0.5244\n",
      "Epoch 196/500\n",
      "60/60 [==============================] - 0s 1ms/step - loss: 0.6932 - accuracy: 0.5313\n",
      "Epoch 197/500\n",
      "60/60 [==============================] - 0s 1ms/step - loss: 0.6945 - accuracy: 0.5053\n",
      "Epoch 198/500\n",
      "60/60 [==============================] - 0s 1ms/step - loss: 0.6930 - accuracy: 0.5024\n",
      "Epoch 199/500\n",
      "60/60 [==============================] - 0s 1ms/step - loss: 0.6916 - accuracy: 0.5031\n",
      "Epoch 200/500\n",
      "60/60 [==============================] - 0s 1ms/step - loss: 0.6930 - accuracy: 0.4946\n",
      "Epoch 201/500\n",
      "60/60 [==============================] - 0s 1ms/step - loss: 0.6934 - accuracy: 0.4972\n",
      "Epoch 202/500\n",
      "60/60 [==============================] - 0s 1ms/step - loss: 0.6932 - accuracy: 0.5091\n",
      "Epoch 203/500\n",
      "60/60 [==============================] - 0s 1ms/step - loss: 0.6927 - accuracy: 0.5125\n",
      "Epoch 204/500\n",
      "60/60 [==============================] - 0s 1ms/step - loss: 0.6930 - accuracy: 0.4839\n",
      "Epoch 205/500\n",
      "60/60 [==============================] - 0s 1ms/step - loss: 0.6930 - accuracy: 0.5102\n",
      "Epoch 206/500\n",
      "60/60 [==============================] - 0s 1ms/step - loss: 0.6936 - accuracy: 0.4798\n",
      "Epoch 207/500\n",
      "60/60 [==============================] - 0s 1ms/step - loss: 0.6926 - accuracy: 0.5186\n",
      "Epoch 208/500\n",
      "60/60 [==============================] - 0s 1ms/step - loss: 0.6951 - accuracy: 0.4835\n",
      "Epoch 209/500\n",
      "60/60 [==============================] - 0s 1ms/step - loss: 0.6925 - accuracy: 0.5016\n",
      "Epoch 210/500\n",
      "60/60 [==============================] - 0s 1ms/step - loss: 0.6940 - accuracy: 0.4841\n",
      "Epoch 211/500\n",
      "60/60 [==============================] - 0s 1ms/step - loss: 0.6922 - accuracy: 0.4963\n",
      "Epoch 212/500\n",
      "60/60 [==============================] - 0s 1ms/step - loss: 0.6938 - accuracy: 0.5091\n",
      "Epoch 213/500\n",
      "60/60 [==============================] - 0s 1ms/step - loss: 0.6915 - accuracy: 0.5189\n",
      "Epoch 214/500\n",
      "60/60 [==============================] - 0s 1ms/step - loss: 0.6934 - accuracy: 0.5281\n",
      "Epoch 215/500\n",
      "60/60 [==============================] - 0s 1ms/step - loss: 0.6931 - accuracy: 0.5097\n",
      "Epoch 216/500\n",
      "60/60 [==============================] - 0s 1ms/step - loss: 0.6920 - accuracy: 0.5163\n",
      "Epoch 217/500\n",
      "60/60 [==============================] - 0s 1ms/step - loss: 0.6922 - accuracy: 0.4912\n",
      "Epoch 218/500\n",
      "60/60 [==============================] - 0s 1ms/step - loss: 0.6938 - accuracy: 0.4912\n",
      "Epoch 219/500\n",
      "60/60 [==============================] - 0s 1ms/step - loss: 0.6942 - accuracy: 0.4764\n",
      "Epoch 220/500\n",
      "60/60 [==============================] - 0s 1ms/step - loss: 0.6924 - accuracy: 0.5381\n",
      "Epoch 221/500\n",
      "60/60 [==============================] - 0s 1ms/step - loss: 0.6909 - accuracy: 0.5386\n",
      "Epoch 222/500\n",
      "60/60 [==============================] - 0s 1ms/step - loss: 0.6935 - accuracy: 0.5040\n",
      "Epoch 223/500\n",
      "60/60 [==============================] - 0s 1ms/step - loss: 0.6939 - accuracy: 0.4860\n",
      "Epoch 224/500\n",
      "60/60 [==============================] - 0s 1ms/step - loss: 0.6928 - accuracy: 0.5076\n",
      "Epoch 225/500\n",
      "60/60 [==============================] - 0s 1ms/step - loss: 0.6932 - accuracy: 0.4983\n",
      "Epoch 226/500\n",
      "60/60 [==============================] - 0s 1ms/step - loss: 0.6926 - accuracy: 0.5225\n",
      "Epoch 227/500\n",
      "60/60 [==============================] - 0s 1ms/step - loss: 0.6928 - accuracy: 0.5111\n",
      "Epoch 228/500\n",
      "60/60 [==============================] - 0s 1ms/step - loss: 0.6916 - accuracy: 0.4856\n",
      "Epoch 229/500\n",
      "60/60 [==============================] - 0s 1ms/step - loss: 0.6918 - accuracy: 0.5033\n",
      "Epoch 230/500\n",
      "60/60 [==============================] - 0s 1ms/step - loss: 0.6937 - accuracy: 0.5207\n",
      "Epoch 231/500\n",
      "60/60 [==============================] - 0s 1ms/step - loss: 0.6922 - accuracy: 0.5040\n",
      "Epoch 232/500\n",
      "60/60 [==============================] - 0s 1ms/step - loss: 0.6931 - accuracy: 0.5266\n",
      "Epoch 233/500\n",
      "60/60 [==============================] - 0s 1ms/step - loss: 0.6929 - accuracy: 0.5119\n",
      "Epoch 234/500\n",
      "60/60 [==============================] - 0s 1ms/step - loss: 0.6921 - accuracy: 0.5059\n",
      "Epoch 235/500\n",
      "60/60 [==============================] - 0s 1ms/step - loss: 0.6925 - accuracy: 0.5268\n",
      "Epoch 236/500\n",
      "60/60 [==============================] - 0s 1ms/step - loss: 0.6922 - accuracy: 0.5174\n",
      "Epoch 237/500\n",
      "60/60 [==============================] - 0s 1ms/step - loss: 0.6922 - accuracy: 0.5226\n",
      "Epoch 238/500\n",
      "60/60 [==============================] - 0s 1ms/step - loss: 0.6949 - accuracy: 0.4674\n",
      "Epoch 239/500\n",
      "60/60 [==============================] - 0s 1ms/step - loss: 0.6921 - accuracy: 0.5145\n",
      "Epoch 240/500\n",
      "60/60 [==============================] - 0s 1ms/step - loss: 0.6915 - accuracy: 0.5657\n",
      "Epoch 241/500\n",
      "60/60 [==============================] - 0s 1ms/step - loss: 0.6955 - accuracy: 0.4970\n",
      "Epoch 242/500\n",
      "60/60 [==============================] - 0s 1ms/step - loss: 0.6921 - accuracy: 0.5134\n",
      "Epoch 243/500\n",
      "60/60 [==============================] - 0s 1ms/step - loss: 0.6937 - accuracy: 0.4784\n",
      "Epoch 244/500\n",
      "60/60 [==============================] - 0s 1ms/step - loss: 0.6938 - accuracy: 0.4908\n",
      "Epoch 245/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "60/60 [==============================] - 0s 1ms/step - loss: 0.6920 - accuracy: 0.5376\n",
      "Epoch 246/500\n",
      "60/60 [==============================] - 0s 1ms/step - loss: 0.6931 - accuracy: 0.5095\n",
      "Epoch 247/500\n",
      "60/60 [==============================] - 0s 1ms/step - loss: 0.6946 - accuracy: 0.4872\n",
      "Epoch 248/500\n",
      "60/60 [==============================] - 0s 1ms/step - loss: 0.6928 - accuracy: 0.5270\n",
      "Epoch 249/500\n",
      "60/60 [==============================] - 0s 1ms/step - loss: 0.6931 - accuracy: 0.4787\n",
      "Epoch 250/500\n",
      "60/60 [==============================] - 0s 1ms/step - loss: 0.6924 - accuracy: 0.5166\n",
      "Epoch 251/500\n",
      "60/60 [==============================] - 0s 1ms/step - loss: 0.6928 - accuracy: 0.5251\n",
      "Epoch 252/500\n",
      "60/60 [==============================] - 0s 1ms/step - loss: 0.6925 - accuracy: 0.5268\n",
      "Epoch 253/500\n",
      "60/60 [==============================] - 0s 1ms/step - loss: 0.6910 - accuracy: 0.5190\n",
      "Epoch 254/500\n",
      "60/60 [==============================] - 0s 1ms/step - loss: 0.6926 - accuracy: 0.4964\n",
      "Epoch 255/500\n",
      "60/60 [==============================] - 0s 1ms/step - loss: 0.6948 - accuracy: 0.4704\n",
      "Epoch 256/500\n",
      "60/60 [==============================] - 0s 1ms/step - loss: 0.6932 - accuracy: 0.5065\n",
      "Epoch 257/500\n",
      "60/60 [==============================] - 0s 1ms/step - loss: 0.6929 - accuracy: 0.5354\n",
      "Epoch 258/500\n",
      "60/60 [==============================] - 0s 1ms/step - loss: 0.6959 - accuracy: 0.4689\n",
      "Epoch 259/500\n",
      "60/60 [==============================] - 0s 1ms/step - loss: 0.6918 - accuracy: 0.5437\n",
      "Epoch 260/500\n",
      "60/60 [==============================] - 0s 1ms/step - loss: 0.6934 - accuracy: 0.4918\n",
      "Epoch 261/500\n",
      "60/60 [==============================] - 0s 1ms/step - loss: 0.6947 - accuracy: 0.4519\n",
      "Epoch 262/500\n",
      "60/60 [==============================] - 0s 1ms/step - loss: 0.6925 - accuracy: 0.4935\n",
      "Epoch 263/500\n",
      "60/60 [==============================] - 0s 1ms/step - loss: 0.6928 - accuracy: 0.5063\n",
      "Epoch 264/500\n",
      "60/60 [==============================] - 0s 1ms/step - loss: 0.6929 - accuracy: 0.5048\n",
      "Epoch 265/500\n",
      "60/60 [==============================] - 0s 1ms/step - loss: 0.6937 - accuracy: 0.5080\n",
      "Epoch 266/500\n",
      "60/60 [==============================] - 0s 1ms/step - loss: 0.6922 - accuracy: 0.5091\n",
      "Epoch 267/500\n",
      "60/60 [==============================] - 0s 1ms/step - loss: 0.6930 - accuracy: 0.5150\n",
      "Epoch 268/500\n",
      "60/60 [==============================] - 0s 1ms/step - loss: 0.6912 - accuracy: 0.5103\n",
      "Epoch 269/500\n",
      "60/60 [==============================] - 0s 1ms/step - loss: 0.6923 - accuracy: 0.4993\n",
      "Epoch 270/500\n",
      "60/60 [==============================] - 0s 1ms/step - loss: 0.6930 - accuracy: 0.4856\n",
      "Epoch 271/500\n",
      "60/60 [==============================] - 0s 1ms/step - loss: 0.6920 - accuracy: 0.4972\n",
      "Epoch 272/500\n",
      "60/60 [==============================] - 0s 1ms/step - loss: 0.6926 - accuracy: 0.5083\n",
      "Epoch 273/500\n",
      "60/60 [==============================] - 0s 1ms/step - loss: 0.6929 - accuracy: 0.5390\n",
      "Epoch 274/500\n",
      "60/60 [==============================] - 0s 1ms/step - loss: 0.6938 - accuracy: 0.5105\n",
      "Epoch 275/500\n",
      "60/60 [==============================] - 0s 1ms/step - loss: 0.6928 - accuracy: 0.5300\n",
      "Epoch 276/500\n",
      "60/60 [==============================] - 0s 1ms/step - loss: 0.6924 - accuracy: 0.5005\n",
      "Epoch 277/500\n",
      "60/60 [==============================] - 0s 1ms/step - loss: 0.6912 - accuracy: 0.5487\n",
      "Epoch 278/500\n",
      "60/60 [==============================] - 0s 1ms/step - loss: 0.6923 - accuracy: 0.5298\n",
      "Epoch 279/500\n",
      "60/60 [==============================] - 0s 1ms/step - loss: 0.6935 - accuracy: 0.4911\n",
      "Epoch 280/500\n",
      "60/60 [==============================] - 0s 1ms/step - loss: 0.6934 - accuracy: 0.5014\n",
      "Epoch 281/500\n",
      "60/60 [==============================] - 0s 1ms/step - loss: 0.6926 - accuracy: 0.5409\n",
      "Epoch 282/500\n",
      "60/60 [==============================] - 0s 1ms/step - loss: 0.6938 - accuracy: 0.4779\n",
      "Epoch 283/500\n",
      "60/60 [==============================] - 0s 1ms/step - loss: 0.6926 - accuracy: 0.5092\n",
      "Epoch 284/500\n",
      "60/60 [==============================] - 0s 1ms/step - loss: 0.6927 - accuracy: 0.5348\n",
      "Epoch 285/500\n",
      "60/60 [==============================] - 0s 1ms/step - loss: 0.6928 - accuracy: 0.5076\n",
      "Epoch 286/500\n",
      "60/60 [==============================] - 0s 1ms/step - loss: 0.6940 - accuracy: 0.5055\n",
      "Epoch 287/500\n",
      "60/60 [==============================] - 0s 1ms/step - loss: 0.6932 - accuracy: 0.5167\n",
      "Epoch 288/500\n",
      "60/60 [==============================] - 0s 1ms/step - loss: 0.6918 - accuracy: 0.5325\n",
      "Epoch 289/500\n",
      "60/60 [==============================] - 0s 1ms/step - loss: 0.6933 - accuracy: 0.5195\n",
      "Epoch 290/500\n",
      "60/60 [==============================] - 0s 1ms/step - loss: 0.6928 - accuracy: 0.5217\n",
      "Epoch 291/500\n",
      "60/60 [==============================] - 0s 1ms/step - loss: 0.6903 - accuracy: 0.5450\n",
      "Epoch 292/500\n",
      "60/60 [==============================] - 0s 1ms/step - loss: 0.6929 - accuracy: 0.5064\n",
      "Epoch 293/500\n",
      "60/60 [==============================] - 0s 1ms/step - loss: 0.6935 - accuracy: 0.5014\n",
      "Epoch 294/500\n",
      "60/60 [==============================] - 0s 1ms/step - loss: 0.6939 - accuracy: 0.5160\n",
      "Epoch 295/500\n",
      "60/60 [==============================] - 0s 1ms/step - loss: 0.6934 - accuracy: 0.4974\n",
      "Epoch 296/500\n",
      "60/60 [==============================] - 0s 1ms/step - loss: 0.6915 - accuracy: 0.5161\n",
      "Epoch 297/500\n",
      "60/60 [==============================] - 0s 1ms/step - loss: 0.6943 - accuracy: 0.5170\n",
      "Epoch 298/500\n",
      "60/60 [==============================] - 0s 1ms/step - loss: 0.6928 - accuracy: 0.5063\n",
      "Epoch 299/500\n",
      "60/60 [==============================] - 0s 1ms/step - loss: 0.6916 - accuracy: 0.4987\n",
      "Epoch 300/500\n",
      "60/60 [==============================] - 0s 1ms/step - loss: 0.6939 - accuracy: 0.5018\n",
      "Epoch 301/500\n",
      "60/60 [==============================] - 0s 1ms/step - loss: 0.6932 - accuracy: 0.5284\n",
      "Epoch 302/500\n",
      "60/60 [==============================] - 0s 1ms/step - loss: 0.6934 - accuracy: 0.5002\n",
      "Epoch 303/500\n",
      "60/60 [==============================] - 0s 1ms/step - loss: 0.6928 - accuracy: 0.5305\n",
      "Epoch 304/500\n",
      "60/60 [==============================] - 0s 1ms/step - loss: 0.6939 - accuracy: 0.5096\n",
      "Epoch 305/500\n",
      "60/60 [==============================] - 0s 1ms/step - loss: 0.6928 - accuracy: 0.5137\n",
      "Epoch 306/500\n",
      "60/60 [==============================] - 0s 1ms/step - loss: 0.6955 - accuracy: 0.4749\n",
      "Epoch 307/500\n",
      "60/60 [==============================] - 0s 1ms/step - loss: 0.6921 - accuracy: 0.5104\n",
      "Epoch 308/500\n",
      "60/60 [==============================] - 0s 1ms/step - loss: 0.6919 - accuracy: 0.5310\n",
      "Epoch 309/500\n",
      "60/60 [==============================] - 0s 1ms/step - loss: 0.6917 - accuracy: 0.4946\n",
      "Epoch 310/500\n",
      "60/60 [==============================] - 0s 1ms/step - loss: 0.6931 - accuracy: 0.5133\n",
      "Epoch 311/500\n",
      "60/60 [==============================] - 0s 1ms/step - loss: 0.6923 - accuracy: 0.5076\n",
      "Epoch 312/500\n",
      "60/60 [==============================] - 0s 1ms/step - loss: 0.6931 - accuracy: 0.4936\n",
      "Epoch 313/500\n",
      "60/60 [==============================] - 0s 1ms/step - loss: 0.6950 - accuracy: 0.4893\n",
      "Epoch 314/500\n",
      "60/60 [==============================] - 0s 1ms/step - loss: 0.6933 - accuracy: 0.5036\n",
      "Epoch 315/500\n",
      "60/60 [==============================] - 0s 1ms/step - loss: 0.6933 - accuracy: 0.5181\n",
      "Epoch 316/500\n",
      "60/60 [==============================] - 0s 1ms/step - loss: 0.6922 - accuracy: 0.5298\n",
      "Epoch 317/500\n",
      "60/60 [==============================] - 0s 1ms/step - loss: 0.6941 - accuracy: 0.4802\n",
      "Epoch 318/500\n",
      "60/60 [==============================] - 0s 1ms/step - loss: 0.6923 - accuracy: 0.5155\n",
      "Epoch 319/500\n",
      "60/60 [==============================] - 0s 1ms/step - loss: 0.6931 - accuracy: 0.5153\n",
      "Epoch 320/500\n",
      "60/60 [==============================] - 0s 1ms/step - loss: 0.6945 - accuracy: 0.4842\n",
      "Epoch 321/500\n",
      "60/60 [==============================] - 0s 1ms/step - loss: 0.6943 - accuracy: 0.4979\n",
      "Epoch 322/500\n",
      "60/60 [==============================] - 0s 1ms/step - loss: 0.6922 - accuracy: 0.5412\n",
      "Epoch 323/500\n",
      "60/60 [==============================] - 0s 1ms/step - loss: 0.6934 - accuracy: 0.5080\n",
      "Epoch 324/500\n",
      "60/60 [==============================] - 0s 1ms/step - loss: 0.6937 - accuracy: 0.4829\n",
      "Epoch 325/500\n",
      "60/60 [==============================] - 0s 1ms/step - loss: 0.6921 - accuracy: 0.5391\n",
      "Epoch 326/500\n",
      "60/60 [==============================] - 0s 1ms/step - loss: 0.6929 - accuracy: 0.5058\n",
      "Epoch 327/500\n",
      "60/60 [==============================] - 0s 1ms/step - loss: 0.6925 - accuracy: 0.4970\n",
      "Epoch 328/500\n",
      "60/60 [==============================] - 0s 1ms/step - loss: 0.6932 - accuracy: 0.4724\n",
      "Epoch 329/500\n",
      "60/60 [==============================] - 0s 1ms/step - loss: 0.6943 - accuracy: 0.4919\n",
      "Epoch 330/500\n",
      "60/60 [==============================] - 0s 1ms/step - loss: 0.6933 - accuracy: 0.4926\n",
      "Epoch 331/500\n",
      "60/60 [==============================] - 0s 1ms/step - loss: 0.6943 - accuracy: 0.4804\n",
      "Epoch 332/500\n",
      "60/60 [==============================] - 0s 1ms/step - loss: 0.6916 - accuracy: 0.5061\n",
      "Epoch 333/500\n",
      "60/60 [==============================] - 0s 1ms/step - loss: 0.6937 - accuracy: 0.4926\n",
      "Epoch 334/500\n",
      "60/60 [==============================] - 0s 1ms/step - loss: 0.6924 - accuracy: 0.4919\n",
      "Epoch 335/500\n",
      "60/60 [==============================] - 0s 1ms/step - loss: 0.6929 - accuracy: 0.5375\n",
      "Epoch 336/500\n",
      "60/60 [==============================] - 0s 1ms/step - loss: 0.6930 - accuracy: 0.4864\n",
      "Epoch 337/500\n",
      "60/60 [==============================] - 0s 1ms/step - loss: 0.6942 - accuracy: 0.5137\n",
      "Epoch 338/500\n",
      "60/60 [==============================] - 0s 1ms/step - loss: 0.6921 - accuracy: 0.5139\n",
      "Epoch 339/500\n",
      "60/60 [==============================] - 0s 1ms/step - loss: 0.6922 - accuracy: 0.5300\n",
      "Epoch 340/500\n",
      "60/60 [==============================] - 0s 1ms/step - loss: 0.6927 - accuracy: 0.4977\n",
      "Epoch 341/500\n",
      "60/60 [==============================] - 0s 1ms/step - loss: 0.6940 - accuracy: 0.5242\n",
      "Epoch 342/500\n",
      "60/60 [==============================] - 0s 1ms/step - loss: 0.6912 - accuracy: 0.5145\n",
      "Epoch 343/500\n",
      "60/60 [==============================] - 0s 1ms/step - loss: 0.6941 - accuracy: 0.4696\n",
      "Epoch 344/500\n",
      "60/60 [==============================] - 0s 1ms/step - loss: 0.6938 - accuracy: 0.4930\n",
      "Epoch 345/500\n",
      "60/60 [==============================] - 0s 1ms/step - loss: 0.6930 - accuracy: 0.5194\n",
      "Epoch 346/500\n",
      "60/60 [==============================] - 0s 1ms/step - loss: 0.6930 - accuracy: 0.4999\n",
      "Epoch 347/500\n",
      "60/60 [==============================] - 0s 1ms/step - loss: 0.6935 - accuracy: 0.5234\n",
      "Epoch 348/500\n",
      "60/60 [==============================] - 0s 1ms/step - loss: 0.6932 - accuracy: 0.5035\n",
      "Epoch 349/500\n",
      "60/60 [==============================] - 0s 1ms/step - loss: 0.6938 - accuracy: 0.4881\n",
      "Epoch 350/500\n",
      "60/60 [==============================] - 0s 1ms/step - loss: 0.6926 - accuracy: 0.4953\n",
      "Epoch 351/500\n",
      "60/60 [==============================] - 0s 1ms/step - loss: 0.6940 - accuracy: 0.4903\n",
      "Epoch 352/500\n",
      "60/60 [==============================] - 0s 1ms/step - loss: 0.6938 - accuracy: 0.5049\n",
      "Epoch 353/500\n",
      "60/60 [==============================] - 0s 1ms/step - loss: 0.6939 - accuracy: 0.5068\n",
      "Epoch 354/500\n",
      "60/60 [==============================] - 0s 1ms/step - loss: 0.6914 - accuracy: 0.5278\n",
      "Epoch 355/500\n",
      "60/60 [==============================] - 0s 1ms/step - loss: 0.6945 - accuracy: 0.4632\n",
      "Epoch 356/500\n",
      "60/60 [==============================] - 0s 1ms/step - loss: 0.6908 - accuracy: 0.5177\n",
      "Epoch 357/500\n",
      "60/60 [==============================] - 0s 1ms/step - loss: 0.6957 - accuracy: 0.4759\n",
      "Epoch 358/500\n",
      "60/60 [==============================] - 0s 1ms/step - loss: 0.6943 - accuracy: 0.5105\n",
      "Epoch 359/500\n",
      "60/60 [==============================] - 0s 1ms/step - loss: 0.6945 - accuracy: 0.4872\n",
      "Epoch 360/500\n",
      "60/60 [==============================] - 0s 1ms/step - loss: 0.6928 - accuracy: 0.5039\n",
      "Epoch 361/500\n",
      "60/60 [==============================] - 0s 1ms/step - loss: 0.6932 - accuracy: 0.5334\n",
      "Epoch 362/500\n",
      "60/60 [==============================] - 0s 1ms/step - loss: 0.6926 - accuracy: 0.5228\n",
      "Epoch 363/500\n",
      "60/60 [==============================] - 0s 1ms/step - loss: 0.6925 - accuracy: 0.5132\n",
      "Epoch 364/500\n",
      "60/60 [==============================] - 0s 1ms/step - loss: 0.6940 - accuracy: 0.4944\n",
      "Epoch 365/500\n",
      "60/60 [==============================] - 0s 1ms/step - loss: 0.6927 - accuracy: 0.5156\n",
      "Epoch 366/500\n",
      "60/60 [==============================] - 0s 1ms/step - loss: 0.6936 - accuracy: 0.4873\n",
      "Epoch 367/500\n",
      "60/60 [==============================] - 0s 1ms/step - loss: 0.6927 - accuracy: 0.5063\n",
      "Epoch 368/500\n",
      "60/60 [==============================] - 0s 1ms/step - loss: 0.6942 - accuracy: 0.4742\n",
      "Epoch 369/500\n",
      "60/60 [==============================] - 0s 1ms/step - loss: 0.6928 - accuracy: 0.4971\n",
      "Epoch 370/500\n",
      "60/60 [==============================] - 0s 1ms/step - loss: 0.6906 - accuracy: 0.5427\n",
      "Epoch 371/500\n",
      "60/60 [==============================] - 0s 1ms/step - loss: 0.6950 - accuracy: 0.4826\n",
      "Epoch 372/500\n",
      "60/60 [==============================] - 0s 1ms/step - loss: 0.6930 - accuracy: 0.5040\n",
      "Epoch 373/500\n",
      "60/60 [==============================] - 0s 1ms/step - loss: 0.6931 - accuracy: 0.4934\n",
      "Epoch 374/500\n",
      "60/60 [==============================] - 0s 1ms/step - loss: 0.6923 - accuracy: 0.5173\n",
      "Epoch 375/500\n",
      "60/60 [==============================] - 0s 1ms/step - loss: 0.6937 - accuracy: 0.4774\n",
      "Epoch 376/500\n",
      "60/60 [==============================] - 0s 1ms/step - loss: 0.6941 - accuracy: 0.4865\n",
      "Epoch 377/500\n",
      "60/60 [==============================] - 0s 1ms/step - loss: 0.6935 - accuracy: 0.4953\n",
      "Epoch 378/500\n",
      "60/60 [==============================] - 0s 1ms/step - loss: 0.6932 - accuracy: 0.5031\n",
      "Epoch 379/500\n",
      "60/60 [==============================] - 0s 1ms/step - loss: 0.6951 - accuracy: 0.4916\n",
      "Epoch 380/500\n",
      "60/60 [==============================] - 0s 1ms/step - loss: 0.6932 - accuracy: 0.4997\n",
      "Epoch 381/500\n",
      "60/60 [==============================] - 0s 1ms/step - loss: 0.6929 - accuracy: 0.4853\n",
      "Epoch 382/500\n",
      "60/60 [==============================] - 0s 1ms/step - loss: 0.6908 - accuracy: 0.5383\n",
      "Epoch 383/500\n",
      "60/60 [==============================] - 0s 1ms/step - loss: 0.6930 - accuracy: 0.4970\n",
      "Epoch 384/500\n",
      "60/60 [==============================] - 0s 1ms/step - loss: 0.6931 - accuracy: 0.4768\n",
      "Epoch 385/500\n",
      "60/60 [==============================] - 0s 1ms/step - loss: 0.6918 - accuracy: 0.5272\n",
      "Epoch 386/500\n",
      "60/60 [==============================] - 0s 1ms/step - loss: 0.6928 - accuracy: 0.5129\n",
      "Epoch 387/500\n",
      "60/60 [==============================] - 0s 1ms/step - loss: 0.6931 - accuracy: 0.4968\n",
      "Epoch 388/500\n",
      "60/60 [==============================] - 0s 1ms/step - loss: 0.6940 - accuracy: 0.4782\n",
      "Epoch 389/500\n",
      "60/60 [==============================] - 0s 1ms/step - loss: 0.6935 - accuracy: 0.5016\n",
      "Epoch 390/500\n",
      "60/60 [==============================] - 0s 1ms/step - loss: 0.6929 - accuracy: 0.5387\n",
      "Epoch 391/500\n",
      "60/60 [==============================] - 0s 1ms/step - loss: 0.6913 - accuracy: 0.5111\n",
      "Epoch 392/500\n",
      "60/60 [==============================] - 0s 1ms/step - loss: 0.6926 - accuracy: 0.4986\n",
      "Epoch 393/500\n",
      "60/60 [==============================] - 0s 1ms/step - loss: 0.6912 - accuracy: 0.5377\n",
      "Epoch 394/500\n",
      "60/60 [==============================] - 0s 1ms/step - loss: 0.6919 - accuracy: 0.5397\n",
      "Epoch 395/500\n",
      "60/60 [==============================] - 0s 1ms/step - loss: 0.6918 - accuracy: 0.5213\n",
      "Epoch 396/500\n",
      "60/60 [==============================] - 0s 1ms/step - loss: 0.6934 - accuracy: 0.4822\n",
      "Epoch 397/500\n",
      "60/60 [==============================] - 0s 1ms/step - loss: 0.6936 - accuracy: 0.5017\n",
      "Epoch 398/500\n",
      "60/60 [==============================] - 0s 1ms/step - loss: 0.6921 - accuracy: 0.5042\n",
      "Epoch 399/500\n",
      "60/60 [==============================] - 0s 1ms/step - loss: 0.6929 - accuracy: 0.5154\n",
      "Epoch 400/500\n",
      "60/60 [==============================] - 0s 1ms/step - loss: 0.6926 - accuracy: 0.5005\n",
      "Epoch 401/500\n",
      "60/60 [==============================] - 0s 1ms/step - loss: 0.6932 - accuracy: 0.5251\n",
      "Epoch 402/500\n",
      "60/60 [==============================] - 0s 1ms/step - loss: 0.6942 - accuracy: 0.4667\n",
      "Epoch 403/500\n",
      "60/60 [==============================] - 0s 1ms/step - loss: 0.6910 - accuracy: 0.5481\n",
      "Epoch 404/500\n",
      "60/60 [==============================] - 0s 1ms/step - loss: 0.6916 - accuracy: 0.5288\n",
      "Epoch 405/500\n",
      "60/60 [==============================] - 0s 1ms/step - loss: 0.6928 - accuracy: 0.5243\n",
      "Epoch 406/500\n",
      "60/60 [==============================] - 0s 1ms/step - loss: 0.6915 - accuracy: 0.5175\n",
      "Epoch 407/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "60/60 [==============================] - 0s 1ms/step - loss: 0.6935 - accuracy: 0.4812\n",
      "Epoch 408/500\n",
      "60/60 [==============================] - 0s 1ms/step - loss: 0.6929 - accuracy: 0.5087\n",
      "Epoch 409/500\n",
      "60/60 [==============================] - 0s 1ms/step - loss: 0.6928 - accuracy: 0.5199\n",
      "Epoch 410/500\n",
      "60/60 [==============================] - 0s 1ms/step - loss: 0.6922 - accuracy: 0.5207\n",
      "Epoch 411/500\n",
      "60/60 [==============================] - 0s 1ms/step - loss: 0.6931 - accuracy: 0.5043\n",
      "Epoch 412/500\n",
      "60/60 [==============================] - 0s 1ms/step - loss: 0.6926 - accuracy: 0.5192\n",
      "Epoch 413/500\n",
      "60/60 [==============================] - 0s 1ms/step - loss: 0.6935 - accuracy: 0.4947\n",
      "Epoch 414/500\n",
      "60/60 [==============================] - 0s 1ms/step - loss: 0.6927 - accuracy: 0.5132\n",
      "Epoch 415/500\n",
      "60/60 [==============================] - 0s 1ms/step - loss: 0.6937 - accuracy: 0.5165\n",
      "Epoch 416/500\n",
      "60/60 [==============================] - 0s 1ms/step - loss: 0.6932 - accuracy: 0.4969\n",
      "Epoch 417/500\n",
      "60/60 [==============================] - 0s 1ms/step - loss: 0.6929 - accuracy: 0.4958\n",
      "Epoch 418/500\n",
      "60/60 [==============================] - 0s 1ms/step - loss: 0.6926 - accuracy: 0.4981\n",
      "Epoch 419/500\n",
      "60/60 [==============================] - 0s 1ms/step - loss: 0.6930 - accuracy: 0.5113\n",
      "Epoch 420/500\n",
      "60/60 [==============================] - 0s 1ms/step - loss: 0.6934 - accuracy: 0.5168\n",
      "Epoch 421/500\n",
      "60/60 [==============================] - 0s 1ms/step - loss: 0.6922 - accuracy: 0.5190\n",
      "Epoch 422/500\n",
      "60/60 [==============================] - 0s 1ms/step - loss: 0.6934 - accuracy: 0.4924\n",
      "Epoch 423/500\n",
      "60/60 [==============================] - 0s 1ms/step - loss: 0.6935 - accuracy: 0.5042\n",
      "Epoch 424/500\n",
      "60/60 [==============================] - 0s 1ms/step - loss: 0.6927 - accuracy: 0.4831\n",
      "Epoch 425/500\n",
      "60/60 [==============================] - 0s 1ms/step - loss: 0.6921 - accuracy: 0.5285\n",
      "Epoch 426/500\n",
      "60/60 [==============================] - 0s 1ms/step - loss: 0.6934 - accuracy: 0.5076\n",
      "Epoch 427/500\n",
      "60/60 [==============================] - 0s 1ms/step - loss: 0.6909 - accuracy: 0.5542\n",
      "Epoch 428/500\n",
      "60/60 [==============================] - 0s 1ms/step - loss: 0.6936 - accuracy: 0.4967\n",
      "Epoch 429/500\n",
      "60/60 [==============================] - 0s 1ms/step - loss: 0.6929 - accuracy: 0.5189\n",
      "Epoch 430/500\n",
      "60/60 [==============================] - 0s 1ms/step - loss: 0.6934 - accuracy: 0.4983\n",
      "Epoch 431/500\n",
      "60/60 [==============================] - 0s 1ms/step - loss: 0.6933 - accuracy: 0.5016\n",
      "Epoch 432/500\n",
      "60/60 [==============================] - 0s 1ms/step - loss: 0.6929 - accuracy: 0.5079\n",
      "Epoch 433/500\n",
      "60/60 [==============================] - 0s 1ms/step - loss: 0.6918 - accuracy: 0.5387\n",
      "Epoch 434/500\n",
      "60/60 [==============================] - 0s 1ms/step - loss: 0.6938 - accuracy: 0.4996\n",
      "Epoch 435/500\n",
      "60/60 [==============================] - 0s 1ms/step - loss: 0.6944 - accuracy: 0.4753\n",
      "Epoch 436/500\n",
      "60/60 [==============================] - 0s 1ms/step - loss: 0.6922 - accuracy: 0.5092\n",
      "Epoch 437/500\n",
      "60/60 [==============================] - 0s 1ms/step - loss: 0.6930 - accuracy: 0.4855\n",
      "Epoch 438/500\n",
      "60/60 [==============================] - 0s 1ms/step - loss: 0.6920 - accuracy: 0.5116\n",
      "Epoch 439/500\n",
      "60/60 [==============================] - 0s 1ms/step - loss: 0.6937 - accuracy: 0.5067\n",
      "Epoch 440/500\n",
      "60/60 [==============================] - 0s 1ms/step - loss: 0.6934 - accuracy: 0.4811\n",
      "Epoch 441/500\n",
      "60/60 [==============================] - 0s 1ms/step - loss: 0.6933 - accuracy: 0.5230\n",
      "Epoch 442/500\n",
      "60/60 [==============================] - 0s 1ms/step - loss: 0.6933 - accuracy: 0.4860\n",
      "Epoch 443/500\n",
      "60/60 [==============================] - 0s 1ms/step - loss: 0.6932 - accuracy: 0.4964\n",
      "Epoch 444/500\n",
      "60/60 [==============================] - 0s 1ms/step - loss: 0.6929 - accuracy: 0.5005\n",
      "Epoch 445/500\n",
      "60/60 [==============================] - 0s 1ms/step - loss: 0.6929 - accuracy: 0.5073\n",
      "Epoch 446/500\n",
      "60/60 [==============================] - 0s 1ms/step - loss: 0.6924 - accuracy: 0.5089\n",
      "Epoch 447/500\n",
      "60/60 [==============================] - 0s 1ms/step - loss: 0.6913 - accuracy: 0.5471\n",
      "Epoch 448/500\n",
      "60/60 [==============================] - 0s 1ms/step - loss: 0.6930 - accuracy: 0.5089\n",
      "Epoch 449/500\n",
      "60/60 [==============================] - 0s 1ms/step - loss: 0.6939 - accuracy: 0.4895\n",
      "Epoch 450/500\n",
      "60/60 [==============================] - 0s 1ms/step - loss: 0.6939 - accuracy: 0.4746\n",
      "Epoch 451/500\n",
      "60/60 [==============================] - 0s 1ms/step - loss: 0.6923 - accuracy: 0.5075\n",
      "Epoch 452/500\n",
      "60/60 [==============================] - 0s 1ms/step - loss: 0.6934 - accuracy: 0.4971\n",
      "Epoch 453/500\n",
      "60/60 [==============================] - 0s 1ms/step - loss: 0.6922 - accuracy: 0.5283\n",
      "Epoch 454/500\n",
      "60/60 [==============================] - 0s 1ms/step - loss: 0.6933 - accuracy: 0.5174\n",
      "Epoch 455/500\n",
      "60/60 [==============================] - 0s 1ms/step - loss: 0.6932 - accuracy: 0.5017\n",
      "Epoch 456/500\n",
      "60/60 [==============================] - 0s 1ms/step - loss: 0.6924 - accuracy: 0.5151\n",
      "Epoch 457/500\n",
      "60/60 [==============================] - 0s 1ms/step - loss: 0.6919 - accuracy: 0.5121\n",
      "Epoch 458/500\n",
      "60/60 [==============================] - 0s 1ms/step - loss: 0.6939 - accuracy: 0.5060\n",
      "Epoch 459/500\n",
      "60/60 [==============================] - 0s 1ms/step - loss: 0.6928 - accuracy: 0.5092\n",
      "Epoch 460/500\n",
      "60/60 [==============================] - 0s 1ms/step - loss: 0.6921 - accuracy: 0.5245\n",
      "Epoch 461/500\n",
      "60/60 [==============================] - 0s 1ms/step - loss: 0.6925 - accuracy: 0.5084\n",
      "Epoch 462/500\n",
      "60/60 [==============================] - 0s 1ms/step - loss: 0.6925 - accuracy: 0.5197\n",
      "Epoch 463/500\n",
      "60/60 [==============================] - 0s 1ms/step - loss: 0.6924 - accuracy: 0.5254\n",
      "Epoch 464/500\n",
      "60/60 [==============================] - 0s 1ms/step - loss: 0.6935 - accuracy: 0.5145\n",
      "Epoch 465/500\n",
      "60/60 [==============================] - 0s 1ms/step - loss: 0.6915 - accuracy: 0.5251\n",
      "Epoch 466/500\n",
      "60/60 [==============================] - 0s 1ms/step - loss: 0.6927 - accuracy: 0.5081\n",
      "Epoch 467/500\n",
      "60/60 [==============================] - 0s 1ms/step - loss: 0.6941 - accuracy: 0.4666\n",
      "Epoch 468/500\n",
      "60/60 [==============================] - 0s 1ms/step - loss: 0.6925 - accuracy: 0.5198\n",
      "Epoch 469/500\n",
      "60/60 [==============================] - 0s 1ms/step - loss: 0.6924 - accuracy: 0.5098\n",
      "Epoch 470/500\n",
      "60/60 [==============================] - 0s 1ms/step - loss: 0.6933 - accuracy: 0.5148\n",
      "Epoch 471/500\n",
      "60/60 [==============================] - 0s 1ms/step - loss: 0.6932 - accuracy: 0.5022\n",
      "Epoch 472/500\n",
      "60/60 [==============================] - 0s 1ms/step - loss: 0.6938 - accuracy: 0.4752\n",
      "Epoch 473/500\n",
      "60/60 [==============================] - 0s 1ms/step - loss: 0.6920 - accuracy: 0.5262\n",
      "Epoch 474/500\n",
      "60/60 [==============================] - 0s 1ms/step - loss: 0.6941 - accuracy: 0.4960\n",
      "Epoch 475/500\n",
      "60/60 [==============================] - 0s 1ms/step - loss: 0.6918 - accuracy: 0.5246\n",
      "Epoch 476/500\n",
      "60/60 [==============================] - 0s 1ms/step - loss: 0.6931 - accuracy: 0.4986\n",
      "Epoch 477/500\n",
      "60/60 [==============================] - 0s 1ms/step - loss: 0.6924 - accuracy: 0.5087\n",
      "Epoch 478/500\n",
      "60/60 [==============================] - 0s 1ms/step - loss: 0.6928 - accuracy: 0.5226\n",
      "Epoch 479/500\n",
      "60/60 [==============================] - 0s 1ms/step - loss: 0.6933 - accuracy: 0.4922\n",
      "Epoch 480/500\n",
      "60/60 [==============================] - 0s 1ms/step - loss: 0.6923 - accuracy: 0.5223\n",
      "Epoch 481/500\n",
      "60/60 [==============================] - 0s 1ms/step - loss: 0.6937 - accuracy: 0.4960\n",
      "Epoch 482/500\n",
      "60/60 [==============================] - 0s 1ms/step - loss: 0.6931 - accuracy: 0.4926\n",
      "Epoch 483/500\n",
      "60/60 [==============================] - 0s 1ms/step - loss: 0.6932 - accuracy: 0.5126\n",
      "Epoch 484/500\n",
      "60/60 [==============================] - 0s 1ms/step - loss: 0.6925 - accuracy: 0.5347\n",
      "Epoch 485/500\n",
      "60/60 [==============================] - 0s 1ms/step - loss: 0.6920 - accuracy: 0.5182\n",
      "Epoch 486/500\n",
      "60/60 [==============================] - 0s 1ms/step - loss: 0.6924 - accuracy: 0.5385\n",
      "Epoch 487/500\n",
      "60/60 [==============================] - 0s 1ms/step - loss: 0.6926 - accuracy: 0.5092\n",
      "Epoch 488/500\n",
      "60/60 [==============================] - 0s 1ms/step - loss: 0.6921 - accuracy: 0.5064\n",
      "Epoch 489/500\n",
      "60/60 [==============================] - 0s 1ms/step - loss: 0.6927 - accuracy: 0.5297\n",
      "Epoch 490/500\n",
      "60/60 [==============================] - 0s 1ms/step - loss: 0.6921 - accuracy: 0.5430\n",
      "Epoch 491/500\n",
      "60/60 [==============================] - 0s 1ms/step - loss: 0.6932 - accuracy: 0.5140\n",
      "Epoch 492/500\n",
      "60/60 [==============================] - 0s 1ms/step - loss: 0.6929 - accuracy: 0.5132\n",
      "Epoch 493/500\n",
      "60/60 [==============================] - 0s 1ms/step - loss: 0.6950 - accuracy: 0.4625\n",
      "Epoch 494/500\n",
      "60/60 [==============================] - 0s 1ms/step - loss: 0.6924 - accuracy: 0.5301\n",
      "Epoch 495/500\n",
      "60/60 [==============================] - 0s 1ms/step - loss: 0.6937 - accuracy: 0.5021\n",
      "Epoch 496/500\n",
      "60/60 [==============================] - 0s 1ms/step - loss: 0.6924 - accuracy: 0.4913\n",
      "Epoch 497/500\n",
      "60/60 [==============================] - 0s 1ms/step - loss: 0.6933 - accuracy: 0.4941\n",
      "Epoch 498/500\n",
      "60/60 [==============================] - 0s 1ms/step - loss: 0.6933 - accuracy: 0.5256\n",
      "Epoch 499/500\n",
      "60/60 [==============================] - 0s 1ms/step - loss: 0.6937 - accuracy: 0.5139\n",
      "Epoch 500/500\n",
      "60/60 [==============================] - 0s 1ms/step - loss: 0.6933 - accuracy: 0.4794\n"
     ]
    }
   ],
   "source": [
    "#wandb.init(project=\"siamese\")\n",
    "history= model.fit([pairTrain[:,0], pairTrain[:,1]], labelTrain[:], batch_size=16, epochs= 500)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 0.          0.         -0.1961326  -0.13259669 -0.3121547  -0.320442\n",
      "  -0.3480663  -0.50276244 -0.39502764 -0.64640886 -0.22928177 -0.5276243\n",
      "  -0.27071825 -0.71823204 -0.27348065 -0.8287293  -0.2679558  -0.93370163\n",
      "  -0.11049724 -0.54972374 -0.1436464  -0.7596685  -0.1519337  -0.8839779\n",
      "  -0.15745856 -1.          0.00276243 -0.53038675 -0.01933702 -0.7237569\n",
      "  -0.03038674 -0.8453039  -0.0441989  -0.9530387   0.12707183 -0.48066297\n",
      "   0.13259669 -0.6325967   0.12983425 -0.7320442   0.12154696 -0.8232044 ]\n",
      " [ 0.          0.          0.14736842 -0.15        0.24736843 -0.32368422\n",
      "   0.19736843 -0.48947367  0.06842105 -0.5736842   0.19736843 -0.5394737\n",
      "   0.25789472 -0.7526316   0.28421053 -0.88684213  0.29210526 -1.\n",
      "   0.05263158 -0.52105266  0.04736842 -0.6763158   0.0868421  -0.49473685\n",
      "   0.10526316 -0.38157895 -0.08157895 -0.45789474 -0.09736842 -0.5631579\n",
      "  -0.01578947 -0.38947368  0.01578947 -0.29210526 -0.21315789 -0.3631579\n",
      "  -0.21052632 -0.46052632 -0.12894736 -0.34736842 -0.09736842 -0.27631578]\n",
      " [ 0.          0.          0.13821138 -0.10162602  0.18699187 -0.25813007\n",
      "   0.07520325 -0.36178863 -0.04674797 -0.43089432  0.18292683 -0.50609756\n",
      "   0.25609756 -0.6910569   0.29471543 -0.8089431   0.31707317 -0.9044715\n",
      "   0.04878049 -0.50609756  0.00609756 -0.7398374  -0.01626016 -0.88414633\n",
      "  -0.04065041 -1.         -0.06910569 -0.4390244  -0.09552845 -0.5081301\n",
      "  -0.03048781 -0.3699187   0.00813008 -0.27642277 -0.16666667 -0.34146342\n",
      "  -0.14837399 -0.3800813  -0.08130081 -0.2784553  -0.03658536 -0.20731707]]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "import pandas as pd\n",
    "\n",
    "#anchors_df = pd.read_csv(r\"E:\\nicholas renotte\\siamese_handgesture_v5_26_6_22\\model\\keypoint_classifier\\anchors.csv\")\n",
    "#test_df = pd.read_csv(r\"E:\\nicholas renotte\\siamese_handgesture_v5_26_6_22\\model\\keypoint_classifier\\test.csv\")\n",
    "\n",
    "#test = test_df.iloc[:,1:]\n",
    "#print(test)\n",
    "\n",
    "#anchor = anchors_df.iloc[:, 1:]\n",
    "#anchor\n",
    "anchors_path = r\"E:\\nicholas renotte\\siamese_handgesture_v5_26_6_22\\model\\keypoint_classifier\\anchors.csv\"\n",
    "test_path = r\"E:\\nicholas renotte\\siamese_handgesture_v5_26_6_22\\model\\keypoint_classifier\\test.csv\"\n",
    "anchors = np.loadtxt(anchors_path, delimiter=',', dtype='float32', usecols=list(range(1, (21 * 2) + 1)))\n",
    "print(anchors)\n",
    "testing = np.loadtxt(test_path, delimiter=',', dtype='float32', usecols=list(range(1, (21 * 2) + 1)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'numpy.ndarray'>\n",
      "1\n"
     ]
    }
   ],
   "source": [
    "# model.summary()\n",
    "\n",
    "out_preds = []\n",
    "for anchor in anchors:\n",
    "#     print(type(testing))\n",
    "#     print(type(anchor))\n",
    "    out_preds.append(model.predict([np.expand_dims(anchor, axis = 0), np.expand_dims(testing, axis = 0)]))\n",
    "    \n",
    "print(np.argmax(out_preds))\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(pairTrain[0][1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(labelTrain[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # loop over a sample of our training pairs\n",
    "# for i in np.random.choice(np.arange(0, len(pairTrain)), size=(49,)):\n",
    "# \t# grab the current image pair and label\n",
    "# \timageA = pairTrain[i][0]\n",
    "# \timageB = pairTrain[i][1]\n",
    "# \tlabel = labelTrain[i]\n",
    "# \t# to make it easier to visualize the pairs and their positive or\n",
    "# \t# negative annotations, we're going to \"pad\" the pair with four\n",
    "# \t# pixels along the top, bottom, and right borders, respectively\n",
    "# \toutput = np.zeros((36, 60), dtype=\"uint8\")\n",
    "# \tpair = np.hstack([imageA, imageB])\n",
    "# \toutput[4:32, 0:56] = pair\n",
    "# \t# set the text label for the pair along with what color we are\n",
    "# \t# going to draw the pair in (green for a \"positive\" pair and\n",
    "# \t# red for a \"negative\" pair)\n",
    "# \ttext = \"neg\" if label[0] == 0 else \"pos\"\n",
    "# \tcolor = (0, 0, 255) if label[0] == 0 else (0, 255, 0)\n",
    "# \t# create a 3-channel RGB image from the grayscale pair, resize\n",
    "# \t# it from 60x36 to 96x51 (so we can better see it), and then\n",
    "# \t# draw what type of pair it is on the image\n",
    "# \tvis = cv2.merge([output] * 3)\n",
    "# \tvis = cv2.resize(vis, (96, 51), interpolation=cv2.INTER_LINEAR)\n",
    "# \tcv2.putText(vis, text, (2, 12), cv2.FONT_HERSHEY_SIMPLEX, 0.75,\n",
    "# \t\tcolor, 2)\n",
    "# \t# add the pair visualization to our list of output images\n",
    "# \timages.append(vis)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # construct the montage for the images\n",
    "# montage = build_montages(images, (96, 51), (7, 7))[0]\n",
    "# # show the output montage\n",
    "# cv2.imshow(\"Siamese Image Pairs\", montage)\n",
    "# cv2.waitKey(0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# モデル構築"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = tf.keras.models.Sequential([\n",
    "    tf.keras.layers.Input((21 * 2, )),\n",
    "    tf.keras.layers.Dropout(0.2),\n",
    "    tf.keras.layers.Dense(20, activation='relu'),\n",
    "    tf.keras.layers.Dropout(0.4),\n",
    "    tf.keras.layers.Dense(10, activation='relu'),\n",
    "    tf.keras.layers.Dense(NUM_CLASSES, activation='softmax')\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.summary()  # tf.keras.utils.plot_model(model, show_shapes=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# モデルチェックポイントのコールバック\n",
    "cp_callback = tf.keras.callbacks.ModelCheckpoint(\n",
    "    model_save_path, verbose=1, save_weights_only=False)\n",
    "# 早期打ち切り用コールバック\n",
    "es_callback = tf.keras.callbacks.EarlyStopping(patience=20, verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# モデルコンパイル\n",
    "model.compile(\n",
    "    optimizer='adam',\n",
    "    loss='sparse_categorical_crossentropy',\n",
    "    metrics=['accuracy']\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# モデル訓練"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "model.fit(\n",
    "    X_train,\n",
    "    y_train,\n",
    "    epochs=1000,\n",
    "    batch_size=128,\n",
    "    validation_data=(X_test, y_test),\n",
    "    callbacks=[cp_callback, es_callback]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# モデル評価\n",
    "val_loss, val_acc = model.evaluate(X_test, y_test, batch_size=128)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 保存したモデルのロード\n",
    "model = tf.keras.models.load_model(model_save_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 推論テスト\n",
    "predict_result = model.predict(np.array([X_test[0]]))\n",
    "print(np.squeeze(predict_result))\n",
    "print(np.argmax(np.squeeze(predict_result)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 混同行列"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import confusion_matrix, classification_report\n",
    "\n",
    "def print_confusion_matrix(y_true, y_pred, report=True):\n",
    "    labels = sorted(list(set(y_true)))\n",
    "    cmx_data = confusion_matrix(y_true, y_pred, labels=labels)\n",
    "    \n",
    "    df_cmx = pd.DataFrame(cmx_data, index=labels, columns=labels)\n",
    " \n",
    "    fig, ax = plt.subplots(figsize=(7, 6))\n",
    "    sns.heatmap(df_cmx, annot=True, fmt='g' ,square=False)\n",
    "    ax.set_ylim(len(set(y_true)), 0)\n",
    "    plt.show()\n",
    "    \n",
    "    if report:\n",
    "        print('Classification Report')\n",
    "        print(classification_report(y_test, y_pred))\n",
    "\n",
    "Y_pred = model.predict(X_test)\n",
    "y_pred = np.argmax(Y_pred, axis=1)\n",
    "\n",
    "print_confusion_matrix(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tensorflow-Lite用のモデルへ変換"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 推論専用のモデルとして保存\n",
    "model.save(model_save_path, include_optimizer=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# モデルを変換(量子化)\n",
    "tflite_save_path = 'model/keypoint_classifier/keypoint_classifier.tflite'\n",
    "\n",
    "converter = tf.lite.TFLiteConverter.from_keras_model(model)\n",
    "converter.optimizations = [tf.lite.Optimize.DEFAULT]\n",
    "tflite_quantized_model = converter.convert()\n",
    "\n",
    "open(tflite_save_path, 'wb').write(tflite_quantized_model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 推論テスト"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'tf' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_11208\\3278931885.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0minterpreter\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlite\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mInterpreter\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmodel_path\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mtflite_save_path\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[0minterpreter\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mallocate_tensors\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'tf' is not defined"
     ]
    }
   ],
   "source": [
    "interpreter = tf.lite.Interpreter(model_path=tflite_save_path)\n",
    "interpreter.allocate_tensors()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 入出力テンソルを取得\n",
    "input_details = interpreter.get_input_details()\n",
    "output_details = interpreter.get_output_details()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Input Shape:\", input_details[0]['shape'])\n",
    "print(\"Input Type:\", input_details[0]['dtype'])\n",
    "print(\"Output Shape:\", output_details[0]['shape'])\n",
    "print(\"Output Type:\", output_details[0]['dtype'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(np.array([X_test[0]]).shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Input details:\", input_details)\n",
    "print(\"Input details index:\", input_details[0]['index'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Output details:\", output_details)\n",
    "print(\"Output details index:\", output_details[0]['index'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "interpreter.set_tensor(input_details[0]['index'], np.array([X_test[0]]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "# 推論実施\n",
    "interpreter.invoke()\n",
    "tflite_results = interpreter.get_tensor(output_details[0]['index'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(tflite_results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(np.squeeze(tflite_results))\n",
    "gg =np.argmax(np.squeeze(tflite_results))\n",
    "print(gg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tensor_details = interpreter.get_tensor_details()\n",
    "for dict in tensor_details:\n",
    "    i = dict['index']\n",
    "    tensor_name = dict['name']\n",
    "    scales = dict['quantization_parameters']['scales']\n",
    "    zero_points = dict['quantization_parameters']['zero_points']\n",
    "    tensor = interpreter.tensor(i)()\n",
    "\n",
    "    print(i, type, tensor_name, scales.shape, zero_points.shape, tensor.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(y_test[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('model/keypoint_classifier/keypoint_classifier_label.csv',\n",
    "            encoding='utf-8-sig') as f:\n",
    "    \n",
    "    keypoint_classifier_labels = csv.reader(f)\n",
    "    keypoint_classifier_labels = [\n",
    "        row[0] for row in keypoint_classifier_labels\n",
    "    ]\n",
    "    print(keypoint_classifier_labels)\n",
    "    \n",
    "aa =keypoint_classifier_labels[gg]\n",
    "print(aa)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "siamese",
   "language": "python",
   "name": "siamese"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
